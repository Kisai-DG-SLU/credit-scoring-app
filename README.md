---
title: Credit Scoring App
emoji: üè¶
colorFrom: blue
colorTo: green
sdk: docker
app_port: 8501
pinned: false
---

# Pr√™t √† d√©penser (Credit Scoring App)

![CI](https://github.com/Kisai-DG-SLU/credit-scoring-app/actions/workflows/ci.yml/badge.svg)
![Deploy](https://github.com/Kisai-DG-SLU/credit-scoring-app/actions/workflows/deploy-hf.yml/badge.svg)
[![Coverage](https://img.shields.io/badge/coverage-79%25-brightgreen)](https://kisai-dg-slu.github.io/credit-scoring-app/)
![Version](https://img.shields.io/github/v/tag/Kisai-DG-SLU/credit-scoring-app?label=version)
![Python](https://img.shields.io/badge/python-3.10-blue)
![License](https://img.shields.io/github/license/Kisai-DG-SLU/credit-scoring-app)

> **Projet 8 - Parcours Data Scientist OpenClassrooms**
>
> Application d'√©valuation du risque de cr√©dit permettant de pr√©dire la probabilit√© de d√©faut de paiement d'un client. Ce projet impl√©mente une approche **MLOps** compl√®te, de l'optimisation des donn√©es au monitoring de la d√©rive (Data Drift) en production.

---

## ‚ö° Points Forts Techniques

- **Performance Backend** : API d√©velopp√©e avec **FastAPI** pour une ex√©cution asynchrone et une validation stricte des donn√©es (Pydantic).
- **Optimisation Donn√©es** : Migration des datasets CSV (> 1 Go) vers **SQLite** index√©, permettant des requ√™tes ultra-rapides (< 10ms) avec une empreinte RAM minimale (< 100 Mo).
- **Dashboard Interactif** : Interface **Streamlit** int√©gr√©e permettant la visualisation des scores et l'explicabilit√© locale (Feature Importance).
- **Monitoring MLOps** : D√©tection automatique du **Data Drift** via **Evidently AI**, avec stockage structur√© des logs de pr√©diction.
- **Conteneurisation** : Image Docker optimis√©e (multi-stage build) pour un d√©ploiement agnostique de l'infrastructure.

## üèó Architecture

Le projet suit une architecture d√©coupl√©e et industrialis√©e :

```
.
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/          # Application FastAPI & Dashboard Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ data/         # Gestion des donn√©es (Conversion SQLite, Logs)
‚îÇ   ‚îú‚îÄ‚îÄ model/        # Logique m√©tier (Chargement, Inf√©rence, Monitoring)
‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Fonctions utilitaires partag√©es
‚îú‚îÄ‚îÄ tests/            # Tests unitaires et d'int√©gration (Coverage > 90%)
‚îú‚îÄ‚îÄ specs/            # Sp√©cifications techniques et fonctionnelles (PRD, Archi)
‚îî‚îÄ‚îÄ .github/          # Workflows CI/CD (Tests, D√©ploiement Cloud)
```

## ‚öôÔ∏è Optimisations & Performance

Pour r√©pondre aux contraintes de production (Cloud Free Tier, Latence faible), plusieurs d√©fis d'ing√©nierie ont √©t√© relev√©s :

1.  **R√©duction de l'Empreinte M√©moire (RAM)**
    *   *Probl√®me* : Le dataset original (CSV) pesait **1.4 Go**, saturant la RAM des petits conteneurs.
    *   *Solution* : Conversion vers **SQLite** index√©. Chargement s√©lectif des clients (< 10ms). Usage RAM < 100 Mo.

2.  **Strat√©gie d'Hybridation des Donn√©es**
    *   **Mode Local (Full)** : Utilise `data/database.sqlite` (**~900 Mo**) pour un acc√®s √† l'int√©gralit√© des 307 511 clients. Id√©al pour le d√©veloppement et la simulation massive.
    *   **Mode Cloud (Lite)** : Utilise `data/database_lite.sqlite` (**~8 Mo**) incluse dans le repository pour garantir un build Docker rapide et stable sur Hugging Face Spaces. L'API bascule automatiquement sur la base disponible au d√©marrage.

3.  **Optimisation de l'Image Docker**
    *   *Probl√®me* : Image initiale > 4 Go incluant les datasets d'entra√Ænement.
    *   *Solution* : Image multi-stage optimis√©e √† **~500 Mo** (Python Slim + SQLite Lite).

4.  **R√©duction de la Latence (Warmup)**
    *   Le syst√®me effectue une pr√©diction "√† vide" au d√©marrage de l'API (Warmup) pour pr√©-charger les mod√®les en cache. Latence moyenne observ√©e : **~270ms**.

## üèóÔ∏è Architecture & Industrialisation

### Inf√©rence & Optimisation (√âtape 4)
- **Format ONNX** : Le mod√®le est converti en format ONNX (`model.onnx`) pour une inf√©rence standardis√©e et performante (**~100x plus rapide** que Scikit-Learn).
- **Cache LRU** : Un m√©canisme de cache (Least Recently Used) est impl√©ment√© pour m√©moriser les r√©sultats SHAP et les scores, r√©duisant la latence √† **0.001ms** pour les requ√™tes r√©p√©t√©es.
- **Warmup** : L'API effectue une pr√©diction "√† blanc" au d√©marrage pour initialiser les ressources (Explainer SHAP) et √©viter la latence du premier appel utilisateur.

### Strat√©gie de Donn√©es Hybride (SQLite)
Pour concilier les limites de stockage de Git/HuggingFace et le besoin de monitoring :
1. **`database_lite.sqlite` (~8 Mo)** : Contient un √©chantillon repr√©sentatif de 1000 clients. Inclus dans le repository pour permettre un build Docker autonome.
2. **`database.sqlite` (Production/Local)** : Utilis√©e pour stocker les logs d'appels r√©els. C'est sur cette base que s'effectue l'analyse de Data Drift.

## üìä Guide d'Interpr√©tation du Monitoring (√âtape 3)

Le suivi de la performance du mod√®le en production repose sur l'outil **Evidently AI**.

### 1. Qu'est-ce que le Data Drift ?
Le "Data Drift" (ou d√©rive des donn√©es) survient lorsque les donn√©es re√ßues en production ("Current") diff√®rent statistiquement des donn√©es sur lesquelles le mod√®le a √©t√© entra√Æn√© ("Reference"). Cela peut d√©grader la performance du mod√®le sans qu'aucune erreur technique ne soit lev√©e.

### 2. Comment fonctionne Evidently AI dans ce projet ?
Nous utilisons le `DataDriftPreset` d'Evidently qui compare deux jeux de donn√©es :
- **Reference Dataset** : Un √©chantillon statique de la base d'entra√Ænement (stock√© dans `database_lite.sqlite`).
- **Current Dataset** : Les logs r√©els des pr√©dictions, stock√©s au fil de l'eau dans la table `prediction_logs` de la base SQLite.

Pour chaque variable cl√© (Top 10 Feature Importance), Evidently applique des tests statistiques (ex: Test de Kolmogorov-Smirnov pour les donn√©es num√©riques) pour d√©terminer si la distribution a chang√© de mani√®re significative (p-value < 0.05).

### 3. Interpr√©ter le Rapport
Le Dashboard g√©n√®re un rapport HTML interactif (`drift_report.html`) accessible via l'interface.
- **Colonne "Drift Detected"** :
    - üî¥ **Drift d√©tect√©** : La distribution a chang√©. Alerte ! Il faut investiguer (changement de population ? erreur de collecte ?).
    - üü¢ **Pas de drift** : Le mod√®le op√®re dans son domaine de validit√© connu.
- **Visualisation** : En cliquant sur une feature, vous pouvez voir l'histogramme comparatif (Reference vs Current) pour comprendre la nature du changement.

**Seuil de Confiance** : L'analyse statistique n'est fiable qu'avec un volume suffisant de donn√©es. Le dashboard affiche un indicateur de confiance (Vert > 500 √©chantillons, Orange < 500).

## ‚úÖ Conformit√© & Robustesse (Points de Vigilance)

L'application r√©pond aux exigences critiques de la mission :
- **Chargement Unique** : Le mod√®le et les artefacts SHAP sont charg√©s via un **Singleton Pattern** au d√©marrage de l'API (`on_event("startup")`). Aucun rechargement n'est effectu√© lors des appels.
- **Gestion des Erreurs** :
    - **Donn√©es manquantes** : L'API convertit automatiquement les NaNs en types compatibles et retourne une pr√©diction robuste.
    - **Identifiants invalides** : Gestion propre des erreurs 404.
    - **Validation types** : Validation stricte des sch√©mas d'entr√©e via Pydantic.
- **S√©curit√©** : Configuration par variables d'environnement (`.env`).

## üõ°Ô∏è Robustesse & Erreurs

- **Validation des Entr√©es** : Utilisation de mod√®les Pydantic pour interdire les requ√™tes malform√©es.
- **Gestion des Cas Limites** :
    *   **Client Inconnu** : Retourne un code `404 Not Found` propre avec message p√©dagogique.
    *   **Donn√©es Manquantes** : Le pipeline de preprocessing g√®re l'imputation automatique des valeurs manquantes via le mod√®le pr√©-entra√Æn√©.
    *   **S√©curit√©** : Logs anonymis√©s (pas de donn√©es personnelles sensibles hors ID technique).


## üõ† Commandes Makefile

| Commande | Description |
| :--- | :--- |
| `make test` | Lance la suite de tests avec rapport de couverture |
| `make lint` | V√©rifie le style du code (Ruff, Black) |
| `make format` | Reformate automatiquement le code |
| `make install` | Initialise l'environnement Conda |
| `make run-api` | Lance le serveur FastAPI |

## üß™ Qualit√©

- **Couverture de tests** : 92% (Pytest).
- **CI/CD** : GitHub Actions automatise les tests et le d√©ploiement sur **Hugging Face Spaces**.
- **URL de Production** : [Acc√©der √† la d√©mo](https://huggingface.co/spaces/damienguesdon/credit-scoring-app)

## üë§ Auteur

**Damien Guesdon**
*Projet r√©alis√© dans le cadre de la formation Data Scientist.*