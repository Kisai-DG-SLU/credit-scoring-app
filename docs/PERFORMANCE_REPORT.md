# üìä Rapport d'Optimisation & Performance

## ‚è±Ô∏è R√©sultats du Benchmark (Audit Final - Phase 17)

Mesures r√©alis√©es sur environnement local (Mac, CPU) via script de benchmark d√©di√© (`scripts/benchmark_resources.py`).

| Op√©ration | M√©thode | Temps Moyen | Gain (Speedup) |
|-----------|---------|-------------|----------------|
| **Inf√©rence** | Joblib (Baseline) | 3.39 ms | 1x (Baseline) |
| **Inf√©rence** | ONNX (Optimis√©) | **0.03 ms** | **~100x** plus rapide |
| **Inf√©rence** | Cached (LRU) | ~0.001 ms | Instantan√© |

> **Note** : Le temps d'inf√©rence ONNX est extr√™mement faible (0.03ms), d√©montrant l'efficacit√© de la compilation du graphe pour des pr√©dictions unitaires.

## üíæ Analyse des Ressources (CPU/RAM)
| M√©trique | Joblib | ONNX | Observation |
|----------|--------|------|-------------|
| **Utilisation RAM** | ~288 MB | ~311 MB | ONNX consomme l√©g√®rement plus (+8%) d√ª au chargement du runtime. |
| **Utilisation CPU** | N√©gligeable | N√©gligeable | Le mod√®le est tr√®s l√©ger, l'inf√©rence ne sature pas le CPU. |
| **Throughput** | ~294 req/s | **~32,000 req/s** | Capacit√© de traitement massivement augment√©e. |

## üöÄ Analyse Technique & Justifications
- **ONNX Runtime** : Le passage √† ONNX offre un gain de performance spectaculaire (x100) sur ce mod√®le tabulaire. Cela s'explique par l'optimisation bas niveau du graphe de calcul et l'absence de l'overhead Python/Pandas inh√©rent √† Scikit-Learn lors des appels `predict`.
- **Cache LRU** : Maintenu pour √©liminer totalement le co√ªt pour les requ√™tes r√©p√©t√©es (UX Dashboard).
- **Architecture CPU** : Les r√©sultats (0.03ms) confirment que l'usage d'un GPU est **inutile** et serait m√™me contre-productif (latence de transfert RAM-VRAM > temps de calcul). L'architecture "CPU-only" est valid√©e pour la production (co√ªt minimal).

## üõ†Ô∏è Configuration d'Optimisation
- **Format** : ONNX Opset 12
- **Moteur** : ONNX Runtime CPU (optimis√© osx-64/linux-64)
- **Cache** : LRU (Least Recently Used) - Taille 128 entr√©es