---
title: Credit Scoring App
emoji: ğŸ¦
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# PrÃªt Ã  dÃ©penser (Credit Scoring App)

![CI](https://github.com/Kisai-DG-SLU/credit-scoring-app/actions/workflows/ci.yml/badge.svg)
![Deploy](https://github.com/Kisai-DG-SLU/credit-scoring-app/actions/workflows/deploy-hf.yml/badge.svg)
![Coverage](https://img.shields.io/badge/coverage-92%25-brightgreen)
![Release](https://img.shields.io/github/v/release/Kisai-DG-SLU/credit-scoring-app)
![Python](https://img.shields.io/badge/python-3.10-blue)
![License](https://img.shields.io/github/license/Kisai-DG-SLU/credit-scoring-app)

> **Projet 7/8 - Parcours Data Scientist OpenClassrooms**
>
> Application d'Ã©valuation du risque de crÃ©dit permettant de prÃ©dire la probabilitÃ© de dÃ©faut de paiement d'un client. Ce projet implÃ©mente une approche **MLOps** complÃ¨te, de l'optimisation des donnÃ©es au monitoring de la dÃ©rive (Data Drift) en production.

---

## âš¡ Points Forts Techniques

- **Performance Backend** : API dÃ©veloppÃ©e avec **FastAPI** pour une exÃ©cution asynchrone et une validation stricte des donnÃ©es (Pydantic).
- **Optimisation DonnÃ©es** : Migration des datasets CSV (> 1 Go) vers **SQLite** indexÃ©, permettant des requÃªtes ultra-rapides (< 10ms) avec une empreinte RAM minimale (< 100 Mo).
- **Dashboard Interactif** : Interface **Streamlit** intÃ©grÃ©e permettant la visualisation des scores et l'explicabilitÃ© locale (Feature Importance).
- **Monitoring MLOps** : DÃ©tection automatique du **Data Drift** via **Evidently AI**, avec stockage structurÃ© des logs de prÃ©diction.
- **Conteneurisation** : Image Docker optimisÃ©e (multi-stage build) pour un dÃ©ploiement agnostique de l'infrastructure.

## ğŸ— Architecture

Le projet suit une architecture dÃ©couplÃ©e et industrialisÃ©e :

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/          # Application FastAPI & Dashboard Streamlit
â”‚   â”œâ”€â”€ data/         # Gestion des donnÃ©es (Conversion SQLite, Logs)
â”‚   â”œâ”€â”€ model/        # Logique mÃ©tier (Chargement, InfÃ©rence, Monitoring)
â”‚   â””â”€â”€ utils/        # Fonctions utilitaires partagÃ©es
â”œâ”€â”€ tests/            # Tests unitaires et d'intÃ©gration (Coverage > 90%)
â”œâ”€â”€ specs/            # SpÃ©cifications techniques et fonctionnelles (PRD, Archi)
â””â”€â”€ .github/          # Workflows CI/CD (Tests, DÃ©ploiement Cloud)
```

## âš™ï¸ Optimisations & Performance

Pour rÃ©pondre aux contraintes de production (Cloud Free Tier, Latence faible), plusieurs dÃ©fis d'ingÃ©nierie ont Ã©tÃ© relevÃ©s :

1.  **RÃ©duction de l'Empreinte MÃ©moire (RAM)**
    *   *ProblÃ¨me* : Le dataset original (CSV) pesait 1.3 Go, saturant la RAM des petits conteneurs.
    *   *Solution* : Conversion vers **SQLite** indexÃ©. Chargement sÃ©lectif des clients (< 10ms). Usage RAM < 100 Mo.

2.  **Optimisation de l'Image Docker**
    *   *ProblÃ¨me* : Image initiale > 4 Go incluant les datasets d'entraÃ®nement.
    *   *Solution* : Exclusion des fichiers lourds (`.dockerignore`) et crÃ©ation d'une **Base Lite** (24 Mo) dÃ©diÃ©e Ã  la dÃ©mo/prod.

3.  **Architecture "All-in-One"**
    *   *Solution* : Orchestration unique via `entrypoint.sh` permettant de servir l'API et le Dashboard dans un seul conteneur, simplifiant le dÃ©ploiement sur les PaaS (Hugging Face Spaces).

## ğŸ¯ Objectifs du Projet
... (existant)

## ğŸ—ï¸ HÃ©ritage et ContinuitÃ© (Projet 6)
Ce projet industrialise les rÃ©sultats validÃ©s lors du **Projet 6 (Scoring CrÃ©dit)** :
- **ModÃ¨le** : LGBMClassifier optimisÃ© (AUC ~0.78).
- **Seuil DÃ©cisionnel** : FixÃ© Ã  **0.49** (optimisation du coÃ»t mÃ©tier : 10x plus de poids sur les Faux NÃ©gatifs).
- **Feature Engineering** : Pipeline complet de 795 features (aggrÃ©gations Bureau, Prev, POS, Installments).
- **ExplicabilitÃ©** : Standardisation du rendu **SHAP Waterfall** (Top 15 features) pour les conseillers.

## ğŸš€ Installation & Usage
... (suite)

### Option 1 : Docker (RecommandÃ© - DÃ©mo All-in-One)
Le projet est entiÃ¨rement conteneurisÃ©. L'image lance automatiquement l'API et le Dashboard.

```bash
# Build de l'image (optimisÃ©e avec base SQLite Lite)
make docker-build

# Lancement du conteneur (API:8000 + Dashboard:8501)
make docker-run
```

### Option 2 : Installation Locale (Conda)
PrÃ©-requis : **Conda** (Miniconda recommandÃ©).

1. **Installer l'environnement**
   ```bash
   make install
   conda activate credit-scoring-app
   ```

2. **DÃ©marrer les services sÃ©parÃ©ment**
   *   **API** : `make run-api` (Port 8000)
   *   **Dashboard** : `streamlit run src/api/dashboard.py` (Port 8501)

## ğŸ“Š Monitoring & Data Drift

Le systÃ¨me inclut un module de monitoring basÃ© sur **Evidently AI**.
- **Base Lite** : Utilise `data/database_lite.sqlite` (24 Mo) pour des performances optimales en dÃ©mo.
- **Logs** : Chaque prÃ©diction est enregistrÃ©e dans une table SQLite structurÃ©e.


## ğŸ›  Commandes Makefile

| Commande | Description |
| :--- | :--- |
| `make test` | Lance la suite de tests avec rapport de couverture |
| `make lint` | VÃ©rifie le style du code (Ruff, Black) |
| `make format` | Reformate automatiquement le code |
| `make install` | Initialise l'environnement Conda |
| `make run-api` | Lance le serveur FastAPI |

## ğŸ§ª QualitÃ©

- **Couverture de tests** : 92% (Pytest).
- **CI/CD** : GitHub Actions automatise les tests et le dÃ©ploiement sur **Hugging Face Spaces**.
- **URL de Production** : [AccÃ©der Ã  la dÃ©mo](https://huggingface.co/spaces/damienguesdon/credit-scoring-app)

## ğŸ‘¤ Auteur

**Damien Guesdon**
*Projet rÃ©alisÃ© dans le cadre de la formation Data Scientist.*