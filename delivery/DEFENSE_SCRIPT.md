# üéôÔ∏è Script de Soutenance : Projet Credit Scoring

## ‚è±Ô∏è Timing Global (30 min)
- **15 min** : Pr√©sentation (Slides + D√©mo)
- **10 min** : Q&A (Chlo√© Dubois)
- **5 min** : D√©brief

---

## üìÖ Partie 1 : Pr√©sentation (15 min)

### 1. Introduction (2 min)
- **Le Contexte** : Besoin du d√©partement "Cr√©dit Express" pour des r√©ponses en quasi temps-r√©el.
- **La Mission** : Industrialiser le mod√®le de scoring (Inf√©rence rapide, Conteneurisation, Monitoring).

### 2. Architecture & Industrialisation (4 min)
- **Choix Technique** : FastAPI pour la performance, Docker pour la portabilit√©.
- **Inf√©rence ONNX** : Pourquoi ? (Standardisation, gain de latence).
- **Scalabilit√©** : Usage du Cache LRU pour SHAP (gain massif sur les calculs r√©p√©t√©s).
- **Architecture Hybride** : Utilisation de SQLite pour le stockage local des logs, garantissant l'ind√©pendance de l'API.

### 3. D√©monstration de l'API (3 min)
- **Action** : Montrer un appel sur Hugging Face ou Localhost.
- **Points √† souligner** : 
    - Rapidit√© de r√©ponse (< 300ms avec SHAP).
    - Qualit√© de l'explication locale (Graphique Waterfall conforme P6).
    - Robustesse (Que se passe-t-il si j'entre un ID inconnu ? -> Erreur 404 propre).

### 4. Monitoring & Data Drift (4 min)
- **Le Concept** : Stockage automatique de 10 features cl√©s dans `prediction_logs`.
- **Simulation** : Lancer le script de simulation (1000 samples) pour montrer un dashboard "vivant".
- **D√©tection de Drift** : Expliquer comment Evidently AI compare le "Current" au "Reference".
- **Gouvernance** : Mentionner l'indicateur de "Confiance Statistique" pour ne pas s'alarmer pr√©matur√©ment.

### 5. Pipeline CI/CD & Tests (2 min)
- **Automatisation** : Chaque commit d√©clenche Pytest (Tests unitaires et de robustesse).
- **Qualit√©** : Couverture > 70% et validation de non-r√©gression.
- **D√©ploiement** : Merge automatique vers la production (Hugging Face).

---

## ‚ùì Partie 2 : Q&A - Les questions de Chlo√©

### Q1 : "Pourquoi utiliser ONNX alors que LightGBM est d√©j√† rapide ?"
- **R√©ponse** : ONNX standardise le format d'√©change. Cela permet de changer de mod√®le (ex: passer √† XGBoost ou PyTorch) sans jamais modifier le code de l'API. C'est un gage de maintenance √† long terme.

### Q2 : "Comment g√©rez-vous le drift si une feature change brutalement ?"
- **R√©ponse** : Le rapport Evidently identifie la feature en cause. Si le drift est majeur (> 50% des features impact√©es), cela d√©clenche une alerte (log/dashboard) et planifie un r√©entra√Ænement du mod√®le sur les nouvelles donn√©es collect√©es.

### Q3 : "Votre API est-elle scalable ?"
- **R√©ponse** : Oui. Gr√¢ce au cache LRU, les requ√™tes r√©p√©t√©es ne consomment plus de CPU. Gr√¢ce √† Docker, on peut multiplier les instances de l'API derri√®re un Load Balancer.

---

## üõ†Ô∏è Cheat Sheet D√©mo (Commandes)

- **Lancer l'API** : `uvicorn src.api.main:app --reload`
- **Lancer le Dashboard** : `streamlit run src/api/dashboard.py`
- **Simuler 1000 clients (Baseline)** : `python src/database/simulation_cli.py baseline`
- **Simuler un Drift** : `python src/database/simulation_cli.py drift`
- **Reset logs** : `python src/database/simulation_cli.py reset`
